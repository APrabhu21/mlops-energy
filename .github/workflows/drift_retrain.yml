name: Drift Detection & Retraining

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  drift-check:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: write
    outputs:
      should_retrain: ${{ steps.drift.outputs.should_retrain }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install dependencies
      run: pip install -q -r requirements.txt
    
    - name: Verify secrets
      run: |
        if [ -z "$DAGSHUB_TOKEN" ]; then
          echo "WARNING: DAGSHUB_TOKEN is not set (needed for retrain)"
        else
          echo "✓ DAGSHUB_TOKEN is configured (length: ${#DAGSHUB_TOKEN})"
        fi
      env:
        DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
      
    - name: Check for existing features data
      run: |
        if [ -f "data/processed/features.parquet" ]; then
          echo "✓ Using committed features.parquet"
          ls -lh data/processed/features.parquet
        else
          echo "✗ No features data found - need to run data ingestion first"
          exit 1
        fi
    
    - name: Generate predictions for drift check
      env:
        MLFLOW_TRACKING_URI: https://dagshub.com/atharvaprabhu6/mlops-energy.mlflow
        MLFLOW_TRACKING_USERNAME: atharvaprabhu6
        MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}
      run: python src/scripts/run_predictions.py
        
    - name: Check drift
      id: drift
      run: python src/scripts/run_drift_check.py
        
    - name: Upload drift report
      uses: actions/upload-artifact@v4
      with:
        name: drift-report
        path: reports/drift_results.json
        
  retrain:
    needs: drift-check
    if: needs.drift-check.outputs.should_retrain == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: write
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install dependencies
      run: pip install -q -r requirements.txt
      
    - name: Check for existing features data
      run: |
        if [ -f "data/processed/features.parquet" ]; then
          echo "✓ Using committed features.parquet"
          ls -lh data/processed/features.parquet
        else
          echo "✗ No features data found - need to run data ingestion first"
          exit 1
        fi
        
    - name: Retrain model
      env:
        MLFLOW_TRACKING_URI: https://dagshub.com/atharvaprabhu6/mlops-energy.mlflow
        DAGSHUB_USER: atharvaprabhu6
        DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        MLFLOW_TRACKING_USERNAME: atharvaprabhu6
        MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}
      run: python src/scripts/run_retraining.py
    
    - name: Regenerate predictions with new champion model
      env:
        MLFLOW_TRACKING_URI: https://dagshub.com/atharvaprabhu6/mlops-energy.mlflow
        MLFLOW_TRACKING_USERNAME: atharvaprabhu6
        MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}
      run: python src/scripts/run_predictions.py
    
    - name: Monitor model performance
      run: python src/scripts/monitor_performance.py
    
    - name: Commit updated predictions
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add data/processed/features.parquet data/reference/reference_features.parquet reports/drift_results.json reports/performance_log.json
        git diff --quiet && git diff --staged --quiet || (git commit -m "Auto-update: regenerate predictions after retraining [skip ci]" && git pull --rebase origin master && git push)
